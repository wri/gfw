{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset / Layer cloning template  \n",
    "This notebook illustrates the steps needed to clone a dataset or a layer in GFW. The [Resource Watch API](https://api.resourcewatch.org/) (where the assets are stored) provides with a [cloning option](https://resource-watch.github.io/doc-api/reference.html#cloning-a-dataset) directly, but the downside is that it requires to clone each component (dataset, layers, metadata, vocabulary) independently, which makes the process cumbersone and much more error-prone.  \n",
    "This notebook provides a template to clone a full dataset (with all its components) using the [**LMIpy library**](https://lmipy.readthedocs.io/en/latest/), which was built for operations with RW datasets and is therefore much more efficient and less error-prone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display\n",
    "import getpass\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMI ver. 0.6.2 ready!\n"
     ]
    }
   ],
   "source": [
    "# Install LMIpy if needed\n",
    "#!pip install LMIPy\n",
    "#!python setup.py develop \n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "import LMIPy as lmi\n",
    "from LMIPy import utils, dataAPI\n",
    "\n",
    "print(f'LMI ver. {lmi.__version__} ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentiction  \n",
    "To modify Resource Watch API's assets, the user needs a RW API account ([see here on creation](https://resource-watch.github.io/doc-api/quickstart.html#2-create-an-account-with-the-rw-api)) with editor privileges, and use it to retrieve the API token key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = getpass.getpass('Login email:')\n",
    "password = getpass.getpass('Login password:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"email\": f\"{email}\",\n",
    "    \"password\": f\"{password}\"\n",
    "}\n",
    "\n",
    "url = f'https://api.resourcewatch.org/auth/login'\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "r = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "\n",
    "API_TOKEN = r.json().get('data').get('token')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone a dataset and release in production \n",
    "On this step, the new datset is cloned and moved from staging to production, while the old dataset is unpublished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) load staging and (current) production datasets (if not already) via id  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = lmi.Dataset('')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prod = lmi.Dataset('')\n",
    "ds_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Clone staging dataset to production  \n",
    "Clone dataset using the `clone` method from LMIpy. Update dataset asset name.  \n",
    "Change environment to `production` afterwards (it does not work during clonning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'SET NAME (v202205)'\n",
    "\n",
    "\n",
    "ds_clone = ds.clone(\n",
    "    token=API_TOKEN,\n",
    "    env='production',\n",
    "    dataset_params={\n",
    "        'name': dataset_name,\n",
    "        'application': ['gfw']\n",
    "    },\n",
    "    clone_children=True\n",
    ")\n",
    "#Environment does not update with clone, needs to be updated after\n",
    "ds_clone.update(update_params={'env':'production'}, token=API_TOKEN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Unpublish old production dataset  \n",
    "Instead of deleting the old dataset, it is suggested to unpublish it. This way, the dataset is not lost and can be recovered as a back-up if necessary.  \n",
    "Update name to indicate old dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prod.update(update_params={\n",
    "    'name': 'SET NAME (DEPRECATED)',\n",
    "    'published':False}, token=API_TOKEN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_gfw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
